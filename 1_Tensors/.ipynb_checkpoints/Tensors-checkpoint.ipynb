{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f34a77f5-6ed1-4839-9583-da83e5c75a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available()=False\n",
      "tensor([[0.6325, 0.8705, 0.3047],\n",
      "        [0.3455, 0.3961, 0.1816],\n",
      "        [0.5411, 0.5020, 0.9090],\n",
      "        [0.9157, 0.3179, 0.7499],\n",
      "        [0.1400, 0.7827, 0.6892]])\n",
      "tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"{torch.cuda.is_available()=}\")\n",
    "# print(f\"{torch.accelerator.is_available()=}\") # Likely not available due to installing the CPU compute version of PyTorch\n",
    "tensor = torch.rand((5, 3))\n",
    "print(tensor)\n",
    "print(f\"tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6994cc-34f3-4b5a-8273-ddcde5bb55cd",
   "metadata": {},
   "source": [
    "# Initializing a Tensor\n",
    "\n",
    "Tensors can be initialized in various ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26376a55-27d3-4a11-b68d-0bd461bfa726",
   "metadata": {},
   "source": [
    "## Directly From Data\n",
    "\n",
    "Data type is inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "134443dc-2634-400f-b023-7640161a8440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72a9b7-efcc-43ca-bb9c-8b9d4fa1a718",
   "metadata": {},
   "source": [
    "## From a NumPy Array\n",
    "\n",
    "Tensors can be created from NumPy arrays (and vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbc4fcb9-8dfb-4442-8086-e10cd7fdcdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1dfe45-678b-4e14-996d-ba7adbf2fde2",
   "metadata": {},
   "source": [
    "## From Another Tensor\n",
    "\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9d74cc5-aa03-4301-973f-9b953cad0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.5716, 0.3434],\n",
      "        [0.3922, 0.1699]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)  # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)  # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082eb58-b678-4fd1-bbb9-f0507fcf3d33",
   "metadata": {},
   "source": [
    "## With Random or Constant Values\n",
    "\n",
    "`shape` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93fd3cdf-9efa-4093-9860-fdab3d13395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2568, 0.0686, 0.5743],\n",
      "        [0.5578, 0.2046, 0.1909]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7373bfb5-b8b5-45da-aff8-61d2092d55f5",
   "metadata": {},
   "source": [
    "# Attributes of a Tensor\n",
    "\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d1baa9f-562b-428e-ac87-aed76f4b54c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((3, 4))\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260b220-1e07-4864-b2d5-62b75e42beed",
   "metadata": {},
   "source": [
    "# Operations on Tensors\n",
    "\n",
    "Over 1200 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively described [here](https://pytorch.org/docs/stable/torch.html).\n",
    "\n",
    "By default, tensors are created on the CPU. We need to explicitly move tensors to the accelerator using the `.to()` method (after checking for accelerator availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34833040-7fe0-498a-bb3a-519814bed603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We move our tensor to the current accelerator if available\n",
    "# if torch.accelerator.is_available():\n",
    "#     tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e97a00-856a-40c0-b13b-58b20ab9d5c0",
   "metadata": {},
   "source": [
    "## Standard NumPy-Like Indexing and Slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09823974-c88a-4f86-b0e0-42db8fffbb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
